import argparse
import json
import numpy as np
import pickle
import h5py
import sys
import tqdm

def parse_args(args=sys.argv[:1]):
    parser = argparse.ArgumentParser()
    parser.add_argument("--patch-file",
                        required=True,
                        help="Patch file generated by collect-patches")
    parser.add_argument("--model",
                        required=True,
                        help="Model file from eflash-train")
    parser.add_argument("--output",
                        required=True,
                        help="Output file of filtered blob coordinates")
    parser.add_argument("--threshold",
                        default=.5,
                        type=float,
                        help="Cutoff threshold for classifier")
    return parser.parse_args(args)

def main(args=sys.argv[1:]):
    opts = parse_args(args)
    patch_file = h5py.File(opts.patch_file, "r")
    with open(opts.model, "rb") as fd:
        model = pickle.load(fd)
    blobs = np.column_stack([patch_file[_][:] for _ in "zyx"])
    all_positive = []
    pca = model["pca"]
    classifier = model["classifier"]
    for i0 in tqdm.tqdm(range(0, len(blobs), 4096)):
        patches = []
        i1 = min(i0 + 4096, len(blobs))
        for p in (patch_file["patches_xy"], patch_file["patches_xz"], patch_file["patches_yz"]):
            patches.append(p[i0:i1].reshape(i1-i0, -1))
        patches = np.hstack(patches)

        pca_patches = pca.transform(patches)
        if classifier.n_features_ == pca_patches.shape[1] + 3:
            # User had --use-position. We do the best we can...
            pca_patches = np.column_stack((pca_patches, blobs[i0:i1, 2], blobs[i0:i1, 1], blobs[i0:i1, 0]))
        probs = classifier.predict_proba(pca_patches)[:, 1]
        all_positive.append(blobs[i0:i1][probs > opts.threshold])
    positive = np.concatenate(all_positive, 0)
    with open(opts.output, "w") as fd:
        json.dump(positive[:, ::-1].tolist(), fd)


if __name__ == "__main__":
    main()
